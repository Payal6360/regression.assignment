{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# theory question"
      ],
      "metadata": {
        "id": "9PW8njAGrzxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1:- What is Simple Linear Regression?\n",
        "\n",
        "Simple Linear Regression is a statistical method to model the relationship between one independent variable (X) and one dependent variable (Y) using a straight line (Y = mX + c).\n",
        "\n"
      ],
      "metadata": {
        "id": "W6g5WmdUr5t9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2:-What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "  . Linearity\n",
        "\n",
        "  . Independence of errors\n",
        "\n",
        "  .  Homoscedasticity (constant variance)\n",
        "\n",
        "  .  Normality of errors\n",
        "\n",
        "  .  No multicollinearity (not applicable here as only 1 feature)"
      ],
      "metadata": {
        "id": "ebb9_TFTsVX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3:-What does the coefficient m represent in the equation Y=mX+c\n",
        "\n",
        "m is the slope of the regression line. It indicates how much Y changes for a unit increase in X."
      ],
      "metadata": {
        "id": "Sjk2VmoSsqvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4:- \u001d\n",
        "E- What does the intercept c represent in the equation Y=mX+c.\n",
        "\n",
        "c is the intercept. It represents the value of Y when X is 0, i.e., where the line crosses the Y-axis.\n"
      ],
      "metadata": {
        "id": "uQFPD0Hbs0iA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5:- How do we calculate the slope m in Simple Linear Regression.\n",
        "\n",
        "\n",
        "       m=\n",
        "n‚àëX\n",
        "2\n",
        " ‚àí(‚àëX)\n",
        "2\n",
        "\n",
        "n‚àëXY‚àí‚àëX‚àëY\n",
        "‚Äã\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "8TIG8JX4tBm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6:- What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "\n",
        "It minimizes the sum of squared differences between actual and predicted Y values. This gives the best-fitting line through the data."
      ],
      "metadata": {
        "id": "HNIYeqsQtfB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7:- How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "\n",
        "R¬≤ (coefficient of determination) measures how well the regression line fits the data. It ranges from 0 to 1. A value of 1 means perfect prediction, 0 means no explanatory power. It shows the proportion of variance in Y explained by X."
      ],
      "metadata": {
        "id": "en-6fmmAtwkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8:--  What is Multiple Linear Regression?\n",
        "\n",
        "It models the relationship between one dependent variable and two or more independent variables using a linear equation:\n",
        "\n",
        "ùëå\n",
        "=\n",
        "ùëè\n",
        "0\n",
        "+\n",
        "ùëè\n",
        "1\n",
        "ùëã\n",
        "1\n",
        "+\n",
        "ùëè\n",
        "2\n",
        "ùëã\n",
        "2\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùëè\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        "Y=b\n",
        "0\n",
        "‚Äã\n",
        " +b\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "1\n",
        "‚Äã\n",
        " +b\n",
        "2\n",
        "‚Äã\n",
        " X\n",
        "2\n",
        "‚Äã\n",
        " +‚ãØ+b\n",
        "n\n",
        "‚Äã\n",
        " X\n",
        "n\n",
        "‚Äã\n"
      ],
      "metadata": {
        "id": "ZGMOXU6Yt5m4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9:-what is the main difference between Simple and Multiple Linear Regression.\n",
        "\n",
        "\n",
        "Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses two or more. The equation in Multiple Linear Regression has multiple slope coefficients.\n",
        "\n"
      ],
      "metadata": {
        "id": "WOMa-PqbuJcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10:- What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Linearity\n",
        "\n",
        "Independence of errors\n",
        "\n",
        "Homoscedasticity\n",
        "\n",
        "Normal distribution of residuals\n",
        "\n",
        "No multicollinearity among predictors"
      ],
      "metadata": {
        "id": "cG43e4bFubR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11:-What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "\n",
        "Heteroscedasticity means that the variance of residuals is not constant across levels of the independent variables. It violates a key regression assumption and can lead to inefficient estimates, biased standard errors, and invalid hypothesis tests (e.g., misleading p-values)."
      ],
      "metadata": {
        "id": "PX6ev8i_ukqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12:- How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "Remove or combine highly correlated variables\n",
        "\n",
        "Use Principal Component Analysis (PCA)\n",
        "\n",
        "Apply Ridge or Lasso Regression\n",
        "\n",
        "Use Variance Inflation Factor (VIF) to detect multicollinearity\n",
        "\n",
        "Collect more data (if possible)"
      ],
      "metadata": {
        "id": "nq7SL6gBvE36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13:- What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "\n",
        "One-Hot Encoding (dummy variables)\n",
        "\n",
        "Label Encoding (for ordinal data)\n",
        "\n",
        "Binary Encoding\n",
        "\n",
        "Target Encoding\n",
        "\n",
        "Avoid dummy variable trap by dropping one column in one-hot encoding"
      ],
      "metadata": {
        "id": "1zkWzqUYvT-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14:-Interaction terms model the combined effect of two or more variables on the target. They help capture non-additive relationships, e.g., if the effect of X‚ÇÅ on Y depends on X‚ÇÇ, use an interaction term like X1 * X2 What is the role of interaction terms in Multiple Linear Regression?"
      ],
      "metadata": {
        "id": "9GlYEBJLvkgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15:- How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "In Simple Linear Regression, the intercept is the predicted Y when X = 0.\n",
        "In Multiple Regression, it‚Äôs the predicted Y when all X variables = 0, which may or may not be meaningful, depending on context."
      ],
      "metadata": {
        "id": "SL3MiYkevxXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16:- What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "\n",
        "The slope indicates how much Y is expected to change for a unit change in X, holding other variables constant. A significant slope (low p-value) means that variable contributes meaningfully to predicting Y.\n",
        "\n"
      ],
      "metadata": {
        "id": "7tmPSaMkv-3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17:- How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "The intercept shows the baseline value of Y when all predictors are 0. It helps anchor the regression line and gives a reference point for interpreting slopes, especially when 0 is a meaningful value for Xs."
      ],
      "metadata": {
        "id": "jLwvdaIswR_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18:- What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "R¬≤ only shows the proportion of variance explained by the model. It doesn‚Äôt indicate whether predictions are accurate, if variables are statistically significant, or if assumptions are met. Also, it increases with more variables, even if they don't improve the model."
      ],
      "metadata": {
        "id": "V6xsxgzowdU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19:-  How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "A large standard error means high uncertainty in the estimate of that coefficient. It suggests the coefficient might not be statistically significant and may vary greatly across samples‚Äîoften caused by multicollinearity or insufficient data"
      ],
      "metadata": {
        "id": "4X6BHvqgwpim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20:-How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "In residual vs. fitted value plots, heteroscedasticity appears as a fan-shaped or funnel-like spread‚Äîresiduals increase or decrease as predicted values change. It violates constant variance assumption, leading to biased standard errors. Correcting it improves the reliability of p-values and confidence intervals."
      ],
      "metadata": {
        "id": "SRj8WPxew790"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z1coOLpXxKIM"
      }
    }
  ]
}